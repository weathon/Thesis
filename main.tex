\documentclass{article}
\usepackage[letter, total={7in, 9in}]{geometry}

\bibliographystyle{naturemag}
\usepackage{graphicx} % Required for inserting images

\title{Converting Molecular Model Images to Digital Representations}
\author{Menki Guo}
\date{January 2024}

\begin{document}

\maketitle
\section*{Abstract}
 
\section{Introduction}
Molecular models are helpful tools in chemistry education as they provide an intuitive way for students to understand the 3D structure compared to 2D molecular structure representation. These models can also assist students with 3D mental operations. Although virtual models could be as effective as concrete models, concrete should be available to students at least at the beginning of the study of new concepts and ideas, as humans sometimes rely concrete objects.\cite{savec_evaluating_2005} However, digital model representation has the benfit that allow students to look up more information about the molecule such as the IUPAC name and the boiling point. Students can also nodify the molecule and observe how it will effect the molecular propities. Thus, it will be benfitical if students can convert concrete molecular models to digital representations. 

Although there are models that are able to convert 2D molecular sturture representations to cooresponding digital representations \cite{swinocsr}\cite{decimer}\cite{chempix}, to the best of our knowledge, there is not a model for 3D molecular models. Closing this gap between 3D molecular models and digital representations is benfitical to chemical education 

Our contribution in this paper can be summaried as:
\begin{itemize}
\item We have constructed two datasets: one computer-rendered 3D molecular models and another consisting of real-world 3D molecular models.
\item We trained a model on top of these two dataset that is capable of converting images of concrete molecular models into their respective SMILES notations. 
\item We applied a mutli-image input method allowing users to capture mutile images of the molecular model to increase the accuracy of the output.
\end{itemize}

\section{Related Work}
\subsection{Swin-OCSR}
\subsection{DECIMER}

\section{Method}
\subsection{Synthetic Dataset}
We downloaded a set of compounds from PubChem \cite{kim_pubchem_2023}, and then these compounds were filtered such that the compounds have at most X atoms \footnote{We did not directly limit the number of atoms on PubChem queries: we limited the number of heavy atoms and molecular weight, which yielded in the limitation of atoms.} and only contains elements of C, O, S, H, N, Cl, Br, F, and P.
After filtering, there are 79,369 compounds in the dataset. We created a Blender Python Script to render these compounds into 3D molecular images. (OpenAI ChatGPT was used to write the building blocks and some logic of the script.) The colour of each atom follows the CPK colouring convention and was according to a couple of online sources and 3D molecular models on the market. For each molecule, we rendered 4 different images at different angles. Detailed render process can be found in our GitHub repository. 
\subsection{Real-World Dataset}
% To collect the real-world dataset, we made a mobile application. 
% Since the most common molecular set kit doe not have S, ...
% Our real-world dataset kept the stereochemistry information however our data
% To make data collection easier, we group similar molecules using GPT. 
% Volunteers from UBCO 
To collect the data set, we create a mobile application using the .js file. Then we recruit volunteers from University of British Columbia Okanagan campus to collect the data. To make the data collection easier, we group similar models together using the generative A list of all the names are given to the GPT and asked to include a sample of the data. This is a sample of the data collected from the GPT. We also allow the volunteers to have a chat with the GPT. So they can give an idea and start talking about it. And they take the next given idea and continue the conversation.
\subsection{Machine Learning Model}
Training a model from randomly initialized parameters are time-consuming, ... 
Our model has an encoder and decoder, the decoder is extracted from \cite{swinocsr} and we tested different sizes Efficient-Net-V2 \cite{effv2}, Swin Transformer \cite{swinocsr}, and MaxViT \cite{tu_maxvit:_2022} for our encoder. The image encoder is from Torch Vision and pre-trained on ImageNet-1K. 
\subsection{Mutli-image input}
\section{Results} 
\section{Conclusion}
\section{Furture Work}
In this project, we did not attempt to recognize chirality and E/Z stereochemical  ..., which is important and the character of 3D models 
The real-world dataset is limited by time and budget, a larger dataset could increase the perfomance
We did not test how well this method will 
Traditional molecular models have some limitations, such as... Alternative models like Snaptoms, train other models, etc
\section*{Acknowledgement}
The computation of this work is mainly performed on UBC Advanced Research Computing, DOI: 10.14288/SOCKEYE.

The author wants to thank Dr. Brian Ganley from the Chemistry Department of the University of Missouri-Columbia for providing use cases and other advice on this project; Dr. Hung-yi Lee from National Taiwan University and Dr. Mu Li from Amazon for their illuminating lectures on YouTube played an essential role in the process of this project; Beiliang Zhao, Peizhi Yan, and Dr. Shan Du from University of British Columbia for mentoring in the process. 

The creation of this project was aided by OpenAI ChatGPT, which contributed to tasks including but not limited to brainstorming, troubleshooting, and coding support.
\bibliography{ref}
\end{document}
